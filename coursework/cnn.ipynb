{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from pylab import *\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import simps\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import itertools\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('data\\WLDataCW.mat')\n",
    "\n",
    "datafile = 'data\\WLDataCW.mat'\n",
    "data_arr = sio.loadmat(datafile)\n",
    "x_ = data_arr['data']\n",
    "y_ = data_arr['label'].reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and test set to contain balanced smaples of Workload 0 and 1 <br>\n",
    "K Cross Validation will be performed further on the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Set : 288\n",
      "Length of Test Set : 72\n"
     ]
    }
   ],
   "source": [
    "low_idx = np.argwhere(y_==0).reshape(-1)\n",
    "medium_idx = np.argwhere(y_==1).reshape(-1)\n",
    "\n",
    "indices = np.random.permutation(low_idx)\n",
    "\n",
    "training_idx , test_idx = indices[:144] , indices[144:]\n",
    "\n",
    "indices = np.random.permutation(medium_idx)\n",
    "training_idx = np.append(training_idx ,indices[:144] )\n",
    "test_idx = np.append(test_idx ,indices[144:])\n",
    "\n",
    "print(\"Length of Train Set :\" ,len(training_idx))\n",
    "print(\"Length of Test Set :\" ,len(test_idx))\n",
    "\n",
    "\n",
    "x_train = x_[:,:,training_idx]\n",
    "y_train = y_[training_idx]\n",
    "\n",
    "x_test = x_[:,:,test_idx]\n",
    "y_test = y_[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset class to load and tranform the EEG signals for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Dataset class to tranform the input and output of Training Data and Labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_arr,y_arr, transform=None, target_transform=None):\n",
    "        self.data = x_arr\n",
    "        self.labels = y_arr.reshape(-1)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.sf = 256\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        arr_list = []\n",
    "        \n",
    "        # for i in  range(self.data.shape[0]):\n",
    "        #     arr = self.bandpower(self.data[i,:,idx],self.sf,None,True)\n",
    "        #     arr_list.append(arr)\n",
    "        # arr = np.array(arr_list).reshape(-1)\n",
    "        # arr = arr.astype(np.float32)\n",
    "        arr = self.data[:,:,idx].reshape(1,62,512)\n",
    "        label = self.labels[idx].astype(np.float32)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return arr, label\n",
    "    \n",
    "    \n",
    "    # The bandpower calculation is inspired by Welch Method described here : https://raphaelvallat.com/bandpower.html\n",
    "    def bandpower(self,data, sf,window_sec=None, relative=False):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : 1d-array\n",
    "            EEG data from a single electrode\n",
    "        sf : float\n",
    "            Sampling frequency\n",
    "        window_sec : float\n",
    "            Length of each window\n",
    "            Default Value, window_sec = (1 / min(band)) * 2\n",
    "        relative : boolean\n",
    "            Relative Band Power(True) or Absolute (False)\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        bp_arr : 1-d array\n",
    "            Array of Absolute and Relative Band Power for Given Frequency Bands - Delta , Theta , Alpha , Beta , Gamma\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        eeg_bands = {'Delta': (1, 4),\n",
    "                    'Theta': (4, 8),\n",
    "                    'Alpha': (8, 12),\n",
    "                    'Beta': (12, 30),\n",
    "                    'Gamma': (30, 120)\n",
    "                    }\n",
    "        \n",
    "        bp_arr = []\n",
    "        for band in ['Delta','Theta','Alpha','Beta','Gamma']:\n",
    "            low, high = eeg_bands[band][0],eeg_bands[band][1]\n",
    "            \n",
    "            # Define window length\n",
    "            if window_sec is not None:\n",
    "                nseg = window_sec * sf\n",
    "            else:\n",
    "                nseg = (2 / low) * sf\n",
    "            if nseg > sf:\n",
    "                nseg = sf\n",
    "            # Compute the modified periodogram (Welch)\n",
    "            freqs, psd = welch(data, sf, nperseg = nseg)\n",
    "\n",
    "            # Frequency resolution\n",
    "            freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "            # Find closest indices of band in frequency vector\n",
    "            idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "\n",
    "            # Integral approximation of the spectrum using Simpson's rule.\n",
    "            bp = simps(psd[idx_band], dx=freq_res)\n",
    "            \n",
    "            # relative to the overal bandpower of signal\n",
    "            if relative:\n",
    "                bp /= simps(psd, dx=freq_res)\n",
    "            bp_arr.append(bp)\n",
    "        return np.array(bp_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2  = nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*12*125, 1200)\n",
    "        self.fc2 = nn.Linear(1200,128)\n",
    "        self.layer_out = nn.Linear(128,1)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.pool(f.relu(self.conv1(inputs)))\n",
    "        x = self.pool(f.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*12*125)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = self.layer_out(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model = BinaryClassification()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassification(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=24000, out_features=1200, bias=True)\n",
       "  (fc2): Linear(in_features=1200, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss , correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        # print(pred.shape)\n",
    "        y = y.unsqueeze(1)\n",
    "        loss = loss_fn(pred,y )\n",
    "        # print(loss)\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (torch.round(pred) == y).type(torch.float).sum().item()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    train_losses.append((train_loss))\n",
    "    train_acc.append(100*correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            y = y.unsqueeze(1)\n",
    "            \n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.round(pred) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    val_losses.append((test_loss))\n",
    "    val_acc.append(100*correct)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 25\n",
    "batch_size = 10\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold no---------0----------------------\n",
      "Epoch 1\n",
      "----------------------------\n",
      "loss: 0.687057  [    0/  144]\n",
      "loss: 0.684569  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.650192 \n",
      "\n",
      "Epoch 2\n",
      "----------------------------\n",
      "loss: 0.558309  [    0/  144]\n",
      "loss: 0.587363  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.606536 \n",
      "\n",
      "Epoch 3\n",
      "----------------------------\n",
      "loss: 0.543863  [    0/  144]\n",
      "loss: 0.492412  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.609872 \n",
      "\n",
      "Epoch 4\n",
      "----------------------------\n",
      "loss: 0.445400  [    0/  144]\n",
      "loss: 0.527410  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.574497 \n",
      "\n",
      "Epoch 5\n",
      "----------------------------\n",
      "loss: 0.439350  [    0/  144]\n",
      "loss: 0.403291  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.590042 \n",
      "\n",
      "Epoch 6\n",
      "----------------------------\n",
      "loss: 0.311536  [    0/  144]\n",
      "loss: 0.365573  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.513265 \n",
      "\n",
      "Epoch 7\n",
      "----------------------------\n",
      "loss: 0.362965  [    0/  144]\n",
      "loss: 0.310160  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.988771 \n",
      "\n",
      "Epoch 8\n",
      "----------------------------\n",
      "loss: 0.557636  [    0/  144]\n",
      "loss: 0.226811  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.542412 \n",
      "\n",
      "Epoch 9\n",
      "----------------------------\n",
      "loss: 0.303124  [    0/  144]\n",
      "loss: 0.161514  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.640530 \n",
      "\n",
      "Epoch 10\n",
      "----------------------------\n",
      "loss: 0.279211  [    0/  144]\n",
      "loss: 0.160422  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.533898 \n",
      "\n",
      "Epoch 11\n",
      "----------------------------\n",
      "loss: 0.143393  [    0/  144]\n",
      "loss: 0.309416  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.490842 \n",
      "\n",
      "Epoch 12\n",
      "----------------------------\n",
      "loss: 0.140798  [    0/  144]\n",
      "loss: 0.180021  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.511197 \n",
      "\n",
      "Epoch 13\n",
      "----------------------------\n",
      "loss: 0.140094  [    0/  144]\n",
      "loss: 0.351384  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.519119 \n",
      "\n",
      "Epoch 14\n",
      "----------------------------\n",
      "loss: 0.079550  [    0/  144]\n",
      "loss: 0.126989  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.537328 \n",
      "\n",
      "Epoch 15\n",
      "----------------------------\n",
      "loss: 0.088642  [    0/  144]\n",
      "loss: 0.098337  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.643161 \n",
      "\n",
      "Epoch 16\n",
      "----------------------------\n",
      "loss: 0.125609  [    0/  144]\n",
      "loss: 0.068010  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.001897 \n",
      "\n",
      "Epoch 17\n",
      "----------------------------\n",
      "loss: 0.352241  [    0/  144]\n",
      "loss: 0.094537  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.568903 \n",
      "\n",
      "Epoch 18\n",
      "----------------------------\n",
      "loss: 0.072995  [    0/  144]\n",
      "loss: 0.044445  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.578585 \n",
      "\n",
      "Epoch 19\n",
      "----------------------------\n",
      "loss: 0.059987  [    0/  144]\n",
      "loss: 0.076292  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.621734 \n",
      "\n",
      "Epoch 20\n",
      "----------------------------\n",
      "loss: 0.115644  [    0/  144]\n",
      "loss: 0.044983  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.620245 \n",
      "\n",
      "Epoch 21\n",
      "----------------------------\n",
      "loss: 0.071211  [    0/  144]\n",
      "loss: 0.034798  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.632890 \n",
      "\n",
      "Epoch 22\n",
      "----------------------------\n",
      "loss: 0.083287  [    0/  144]\n",
      "loss: 0.066357  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.596529 \n",
      "\n",
      "Epoch 23\n",
      "----------------------------\n",
      "loss: 0.030549  [    0/  144]\n",
      "loss: 0.042995  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.629008 \n",
      "\n",
      "Epoch 24\n",
      "----------------------------\n",
      "loss: 0.052581  [    0/  144]\n",
      "loss: 0.024497  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.631528 \n",
      "\n",
      "Epoch 25\n",
      "----------------------------\n",
      "loss: 0.047559  [    0/  144]\n",
      "loss: 0.028238  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.636465 \n",
      "\n",
      "------------fold no---------1----------------------\n",
      "Epoch 1\n",
      "----------------------------\n",
      "loss: 0.634298  [    0/  144]\n",
      "loss: 0.687265  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 0.704056 \n",
      "\n",
      "Epoch 2\n",
      "----------------------------\n",
      "loss: 0.544234  [    0/  144]\n",
      "loss: 0.560701  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.636891 \n",
      "\n",
      "Epoch 3\n",
      "----------------------------\n",
      "loss: 0.467158  [    0/  144]\n",
      "loss: 0.858100  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.619784 \n",
      "\n",
      "Epoch 4\n",
      "----------------------------\n",
      "loss: 0.481657  [    0/  144]\n",
      "loss: 0.546020  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.554530 \n",
      "\n",
      "Epoch 5\n",
      "----------------------------\n",
      "loss: 0.426459  [    0/  144]\n",
      "loss: 0.426912  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 0.799680 \n",
      "\n",
      "Epoch 6\n",
      "----------------------------\n",
      "loss: 0.721413  [    0/  144]\n",
      "loss: 0.426570  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.519730 \n",
      "\n",
      "Epoch 7\n",
      "----------------------------\n",
      "loss: 0.379668  [    0/  144]\n",
      "loss: 0.216677  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.775971 \n",
      "\n",
      "Epoch 8\n",
      "----------------------------\n",
      "loss: 0.415917  [    0/  144]\n",
      "loss: 0.344382  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.492054 \n",
      "\n",
      "Epoch 9\n",
      "----------------------------\n",
      "loss: 0.297671  [    0/  144]\n",
      "loss: 0.164885  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.553127 \n",
      "\n",
      "Epoch 10\n",
      "----------------------------\n",
      "loss: 0.212534  [    0/  144]\n",
      "loss: 0.343386  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 0.889591 \n",
      "\n",
      "Epoch 11\n",
      "----------------------------\n",
      "loss: 1.296464  [    0/  144]\n",
      "loss: 0.195741  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.509531 \n",
      "\n",
      "Epoch 12\n",
      "----------------------------\n",
      "loss: 0.202077  [    0/  144]\n",
      "loss: 0.326493  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.590551 \n",
      "\n",
      "Epoch 13\n",
      "----------------------------\n",
      "loss: 0.167163  [    0/  144]\n",
      "loss: 0.202219  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.432597 \n",
      "\n",
      "Epoch 14\n",
      "----------------------------\n",
      "loss: 0.166361  [    0/  144]\n",
      "loss: 0.192133  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.435240 \n",
      "\n",
      "Epoch 15\n",
      "----------------------------\n",
      "loss: 0.180721  [    0/  144]\n",
      "loss: 0.140039  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.546276 \n",
      "\n",
      "Epoch 16\n",
      "----------------------------\n",
      "loss: 0.234332  [    0/  144]\n",
      "loss: 0.125068  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.471834 \n",
      "\n",
      "Epoch 17\n",
      "----------------------------\n",
      "loss: 0.309583  [    0/  144]\n",
      "loss: 0.101876  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.434625 \n",
      "\n",
      "Epoch 18\n",
      "----------------------------\n",
      "loss: 0.089450  [    0/  144]\n",
      "loss: 0.108113  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.411537 \n",
      "\n",
      "Epoch 19\n",
      "----------------------------\n",
      "loss: 0.104779  [    0/  144]\n",
      "loss: 0.097368  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.434964 \n",
      "\n",
      "Epoch 20\n",
      "----------------------------\n",
      "loss: 0.084002  [    0/  144]\n",
      "loss: 0.055943  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.895438 \n",
      "\n",
      "Epoch 21\n",
      "----------------------------\n",
      "loss: 0.162416  [    0/  144]\n",
      "loss: 0.099447  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.420008 \n",
      "\n",
      "Epoch 22\n",
      "----------------------------\n",
      "loss: 0.092085  [    0/  144]\n",
      "loss: 0.025725  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.546080 \n",
      "\n",
      "Epoch 23\n",
      "----------------------------\n",
      "loss: 0.082681  [    0/  144]\n",
      "loss: 0.089993  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.460177 \n",
      "\n",
      "Epoch 24\n",
      "----------------------------\n",
      "loss: 0.067075  [    0/  144]\n",
      "loss: 0.038073  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.651818 \n",
      "\n",
      "Epoch 25\n",
      "----------------------------\n",
      "loss: 0.037214  [    0/  144]\n",
      "loss: 0.036311  [  100/  144]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.473782 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=2,shuffle=True)\n",
    "\n",
    "for fold,(train_idx,test_idx) in enumerate(kfold.split(x_train[0,0,:])):\n",
    "    print('------------fold no---------{}----------------------'.format(fold))\n",
    "  \n",
    "    # train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    # test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    X = x_train[:,:,train_idx]\n",
    "    Y = y_train[train_idx]\n",
    "    x_val = x_train[:,:,test_idx]\n",
    "    y_val = y_train[test_idx]\n",
    "    # print(X.shape)\n",
    "    # print(Y.shape)\n",
    "    # print(x_val.shape)\n",
    "    # print(y_val.shape)\n",
    "    # print(train_idx)\n",
    "    # print(test_idx)\n",
    "    \n",
    "    train_dataloader = DataLoader(CustomDataset(X , Y), batch_size = batch_size, shuffle=True)\n",
    "    val_dataloader  = DataLoader(CustomDataset(x_val , y_val), batch_size = batch_size, shuffle=True)\n",
    "    \n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        \n",
    "        print(f\"Epoch {t+1}\\n----------------------------\")\n",
    "        train_loop(train_dataloader,model,loss_fn,optimizer)\n",
    "        test_loop(val_dataloader,model,loss_fn)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.94444444444444"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader, model):\n",
    "    model.eval()\n",
    "    pred_l = []\n",
    "    with torch.no_grad():\n",
    "        for X, _ in dataloader:\n",
    "            pred = model(X)\n",
    "            pred_l.append(torch.round(pred).item())\n",
    "    return np.array(pred_l,dtype=uint8)\n",
    "\n",
    "test_loader  = DataLoader(CustomDataset(x_test , y_test))\n",
    "\n",
    "pred = predict(test_loader,model)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "   \n",
    "    ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(classes)\n",
    "    ax.yaxis.set_ticklabels(classes)\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n",
    "\n",
    "def accuray_report(pred,true,report=True):\n",
    "    if report:\n",
    "      print(10*'*')\n",
    "      print('Confusion Matrix')\n",
    "      print(10*'*')\n",
    "      cm = confusion_matrix(true , pred)\n",
    "      print(cm)\n",
    "      plot_confusion_matrix(cm,['Low','Medium'])\n",
    "      \n",
    "      print(10*'*')\n",
    "      print('Classification Report')\n",
    "      print(10*'*')\n",
    "      print(classification_report(true , pred ))\n",
    "    return accuracy_score(true,pred)\n",
    "\n",
    "def save_plot_graphs(experiment_name , train_acc,val_acc,train_losses,val_losses):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
    "    ax1.plot(train_losses, label='Training loss')\n",
    "    ax1.plot(val_losses, label='Validation loss')\n",
    "    # ax1.xlabel('Epochs')\n",
    "    # ax1.ylabel('Loss Value')\n",
    "    ax1.set(xlabel='Epochs', ylabel='Loss Value')\n",
    "    ax1.legend()\n",
    "    \n",
    "    \n",
    "    ax2.plot(train_acc, label='Training Accuracy')\n",
    "    ax2.plot(val_acc, label='Validation Accuracy')\n",
    "    # ax2.xlabel('Epochs')\n",
    "    # ax2.ylabel('Accuracy')\n",
    "    ax2.set(xlabel='Epochs', ylabel='Loss Value')\n",
    "    ax2.legend()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Confusion Matrix\n",
      "**********\n",
      "[[26 10]\n",
      " [ 2 34]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Classification Report\n",
      "**********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81        36\n",
      "           1       0.77      0.94      0.85        36\n",
      "\n",
      "    accuracy                           0.83        72\n",
      "   macro avg       0.85      0.83      0.83        72\n",
      "weighted avg       0.85      0.83      0.83        72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuray_report(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_plot_graphs('experiment_name' , train_acc,val_acc,train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f73ca796a9fc520160c68fb082adeee8cca72dd22cecda376fb3fa4e6ba6f920"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
